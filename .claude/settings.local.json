{
  "permissions": {
    "allow": [
      "Bash(curl:*)",
      "Bash(lsof:*)",
      "Bash(kubectl describe:*)",
      "Bash(kubectl logs:*)",
      "Bash(kubectl get:*)",
      "Bash(python3:*)",
      "Bash(oc logs:*)",
      "Bash(chmod:*)",
      "Bash(source .env)",
      "Bash(echo \"=== Question 1: Bat and Ball ===\" QUESTION=\"A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?\")",
      "Bash(echo \"--- INFERENCE_MODEL \\($INFERENCE_MODEL\\) ---\" curl -sS $LLAMA_STACK_BASE_URL/v1/chat/completions -H \"Content-Type: application/json\" -H \"Authorization: Bearer fake\" -d \"{\n       \"\"model\"\": \"\"$INFERENCE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(echo \"\" echo \"--- JUDGE_MODEL \\($JUDGE_MODEL\\) ---\" curl -sS $LLAMA_STACK_BASE_URL/v1/chat/completions -H \"Content-Type: application/json\" -H \"Authorization: Bearer fake\" -d \"{\n       \"\"model\"\": \"\"$JUDGE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(LLAMA_STACK_BASE_URL=\"http://localhost:8321\" INFERENCE_MODEL=\"vllm/qwen3-14b-gaudi\" JUDGE_MODEL=\"vllm/llama-scout-17b\")",
      "Bash(echo \"=== Question 1: Bat and Ball ===\" QUESTION=\"A bat and a ball cost 1.10 dollars in total. The bat costs 1.00 dollar more than the ball. How much does the ball cost?\")",
      "Bash(echo \"--- INFERENCE_MODEL \\($INFERENCE_MODEL\\) ---\" curl -sS \"$LLAMA_STACK_BASE_URL/v1/chat/completions\" -H \"Content-Type: application/json\" -H \"Authorization: Bearer fake\" -d \"{\n       \"\"model\"\": \"\"$INFERENCE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(echo \"\" echo \"--- JUDGE_MODEL \\($JUDGE_MODEL\\) ---\" curl -sS \"$LLAMA_STACK_BASE_URL/v1/chat/completions\" -H \"Content-Type: application/json\" -H \"Authorization: Bearer fake\" -d \"{\n       \"\"model\"\": \"\"$JUDGE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(LLAMA_STACK_BASE_URL=\"http://localhost:8321\")",
      "Bash(INFERENCE_MODEL=\"vllm/qwen3-14b-gaudi\")",
      "Bash(JUDGE_MODEL=\"vllm/llama-scout-17b\")",
      "Bash(QUESTION=\"A bat and a ball cost 1.10 dollars in total. The bat costs 1.00 dollar more than the ball. How much does the ball cost?\")",
      "Bash(echo:*)",
      "mcp__context7__resolve-library-id",
      "mcp__context7__get-library-docs",
      "Bash(source:*)",
      "Bash(python:*)",
      "Bash(LLAMA_STACK_BASE_URL:*)",
      "Bash(jq:*)",
      "Bash(podman build:*)",
      "Bash(podman push:*)",
      "Bash(helm upgrade:*)",
      "Bash(oc rollout status:*)",
      "Bash(oc whoami:*)",
      "Bash(oc get pod:*)",
      "Bash(oc delete pod:*)",
      "Bash(podman inspect:*)",
      "Bash(podman tag:*)",
      "Bash(podman images:*)",
      "Bash(skopeo inspect:*)",
      "Bash(oc exec:*)",
      "Bash(oc get pods:*)",
      "Bash(oc get svc:*)",
      "Bash(oc get routes:*)",
      "Bash(oc get:*)",
      "Bash(export LLAMA_STACK_BASE_URL=http://llamastack-distribution-vllm-service:8321 export INFERENCE_MODEL=vllm/qwen3-14b-gaudi export QUESTION=\"what model are you?\" export API_KEY=\"not applicable\" curl -sS $LLAMA_STACK_BASE_URL/v1/chat/completions -H \"Content-Type: application/json\" -H \"Authorization: Bearer $API_KEY\" -d \"{\n       \"\"model\"\": \"\"$INFERENCE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(export LLAMA_STACK_BASE_URL=\"http://localhost:8321\")",
      "Bash(export API_KEY=\"not-applicable\")",
      "Bash(LLAMA_STACK_BASE_URL=\"http://localhost:8321\"  API_KEY=\"not-applicable\"  INFERENCE_MODEL=\"$INFERENCE_MODEL:-vllm/qwen3-14b-gaudi\"  QUESTION=\"$QUESTION:-Hello, what model are you?\"  curl:*)",
      "Bash(export LLAMA_STACK_BASE_URL=\"http://localhost:8321\" export API_KEY=\"not-applicable\" export INFERENCE_MODEL=\"vllm/qwen3-14b-gaudi\" export QUESTION=\"Hello, what model are you?\" curl -sS \"$LLAMA_STACK_BASE_URL/v1/chat/completions\" -H \"Content-Type: application/json\" -H \"Authorization: Bearer $API_KEY\" -d \"{\n       \"\"model\"\": \"\"$INFERENCE_MODEL\"\",\n       \"\"messages\"\": [{\"\"role\"\": \"\"user\"\", \"\"content\"\": \"\"$QUESTION\"\"}],\n       \"\"temperature\"\": 0.0\n     }\")",
      "Bash(git check-ignore:*)",
      "Bash(git ls-tree:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(oc describe:*)",
      "Bash(oc patch:*)",
      "Bash(oc run:*)",
      "Bash(oc debug:*)",
      "Bash(oc apply:*)",
      "Bash(oc rollout:*)",
      "Bash(oc project:*)",
      "Bash(oc delete:*)",
      "WebSearch",
      "WebFetch(domain:access.redhat.com)",
      "WebFetch(domain:docs.redhat.com)",
      "Bash(export LLAMA_STACK_BASE_URL=http://localhost:8321)",
      "Bash(export INFERENCE_MODEL=vllm/qwen3-14b)",
      "Bash(export QUESTION=\"what model are you?\")",
      "Bash(git checkout:*)",
      "Bash(git fetch:*)",
      "Bash(git restore:*)",
      "Bash(oc login:*)",
      "Bash(git pull:*)",
      "Bash(./RHOAI-genAI-studio/view-project-labels.sh)"
    ],
    "deny": [],
    "ask": []
  }
}
