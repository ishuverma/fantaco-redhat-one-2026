# LLM Configuration
API_KEY=your_api_key_here


# Using Ollama 
# INFERENCE_MODEL=qwen3:14b-q8_0
# BASE_URL=http://localhost:11434/v1

INFERENCE_MODEL=vllm/qwen3-14b

# Using port-forward technique
# BASE_URL=http://localhost:8321/v1

# Inside of workshop cluster
BASE_URL=http://llamastack-distribution-vllm-service:8321/v1


# Application Configuration
PORT=8002
