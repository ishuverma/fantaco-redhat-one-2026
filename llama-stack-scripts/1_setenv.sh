# source setenv.sh
export LLAMA_STACK_BASE_URL=http://localhost:8321
# export INFERENCE_MODEL=ollama/llama3.2:3b
export INFERENCE_MODEL=vllm/llama-4-scout-17b-16e-w4a16